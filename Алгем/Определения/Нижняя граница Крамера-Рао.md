---
aliases:
  - нижняя граница Крамера-Рао
  - неравенство Крамера-Рао
  - Cramér–Rao bound
  - CRB
---
**Нижняя граница Крамера-Рао (CRB)** — это фундаментальный результат в теории статистического оценивания, который устанавливает предел снизу для дисперсии любой [[Несмещенная оценка|несмещённой оценки]] детерминированного параметра. Иными словами, она показывает, какой минимальной дисперсии (т.е. максимальной точности) в принципе можно достичь при оценивании параметра.

## Основная идея

Пусть $\hat{\theta}$ — это любая [[Несмещенная оценка|несмещённая оценка]] неизвестного параметра $\theta$, полученная на основе выборки $X$. Тогда её дисперсия не может быть меньше, чем величина, обратная **информации Фишера**.

### Информация Фишера

**Информация Фишера** $I(\theta)$ — это величина, которая показывает, сколько информации о параметре $\theta$ содержится в одном наблюдении (или во всей выборке). Чем больше информации, тем точнее можно оценить параметр.

Для одного наблюдения $x$ из [[Распределение|распределения]] $p(x|\theta)$ информация Фишера определяется как дисперсия **функции вклада (score function)**, которая является производной логарифма правдоподобия по параметру:
$$
I(\theta) = E\left[ \left( \frac{\partial}{\partial \theta} \ln p(x|\theta) \right)^2 \right]
$$
При определённых условиях регулярности, которые обычно выполняются, информацию Фишера можно вычислить проще, через вторую производную:
$$
I(\theta) = -E\left[ \frac{\partial^2}{\partial \theta^2} \ln p(x|\theta) \right]
$$
Для независимой выборки $X = (x_1, \dots, x_n)$ информация Фишера аддитивна: $I_n(\theta) = n \cdot I(\theta)$.

### Неравенство Крамера-Рао

Неравенство утверждает, что для любой [[Несмещенная оценка|несмещённой оценки]] $\hat{\theta}$ параметра $\theta$:
$$
\text{Var}(\hat{\theta}) \ge \frac{1}{I_n(\theta)} = \frac{1}{n \cdot I(\theta)}
$$

## Связь с эффективностью

*   [[Эффективная оценка|Эффективной оценкой]] называется такая [[Несмещенная оценка|несмещённая оценка]], дисперсия которой достигает нижней границы Крамера-Рао.
*   Оценки, полученные [[Метод максимального правдоподобия|методом максимального правдоподобия]], являются асимптотически [[Эффективная оценка|эффективными]], то есть их дисперсия стремится к CRB при увеличении размера выборки $n \to \infty$.

## Пример: Оценка параметра Бернулли

Рассмотрим тот же пример, что и в [[Метод максимального правдоподобия|ММП]]: оцениваем вероятность успеха $p$ в распределении Бернулли.

1.  **Логарифм правдоподобия для одного наблюдения** $x \in \{0, 1\}$:
    $$
    \ln p(x|p) = x \ln p + (1-x) \ln(1-p)
    $$

2.  **Вторая производная**:
    $$
    \frac{\partial^2}{\partial p^2} \ln p(x|p) = -\frac{x}{p^2} - \frac{1-x}{(1-p)^2}
    $$

3.  **Информация Фишера**:
    $$
    I(p) = -E\left[ -\frac{X}{p^2} - \frac{1-X}{(1-p)^2} \right] = \frac{E[X]}{p^2} + \frac{1-E[X]}{(1-p)^2}
    $$
    Поскольку для Бернулли $E[X] = p$, получаем:
    $$
    I(p) = \frac{p}{p^2} + \frac{1-p}{(1-p)^2} = \frac{1}{p} + \frac{1}{1-p} = \frac{1}{p(1-p)}
    $$

4.  **Нижняя граница Крамера-Рао для выборки размера $n$**:
    $$
    \text{CRB} = \frac{1}{n \cdot I(p)} = \frac{p(1-p)}{n}
    $$

5.  **Сравнение с оценкой [[Метод максимального правдоподобия|ММП]]**:
    Оценка [[Метод максимального правдоподобия|ММП]] для этого случая — выборочное среднее $\hat{p} = \frac{1}{n}\sum x_i$. Эта оценка является [[Несмещенная оценка|несмещённой]]. Её дисперсия равна:
    $$
    \text{Var}(\hat{p}) = \text{Var}\left(\frac{1}{n}\sum x_i\right) = \frac{1}{n^2} \sum \text{Var}(x_i) = \frac{n \cdot p(1-p)}{n^2} = \frac{p(1-p)}{n}
    $$
    Дисперсия оценки [[Метод максимального правдоподобия|ММП]] в точности равна нижней границе Крамера-Рао. Следовательно, выборочное среднее является **[[Эффективная оценка|эффективной оценкой]]** для параметра $p$ распределения Бернулли.