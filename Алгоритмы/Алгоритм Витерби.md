---
aliases:
  - алгоритм Витерби
  - Viterbi algorithm
---
**Алгоритм Витерби** — это алгоритм динамического программирования для нахождения наиболее вероятной последовательности скрытых состояний (известной как **путь Витерби**), которая привела к наблюдаемой последовательности событий. Он используется для решения **задачи декодирования** в [[Скрытая марковская модель|скрытых марковских моделях (HMM)]].

## Основная идея

Наивный подход к поиску лучшей последовательности скрытых состояний — перебрать все возможные последовательности, вычислить вероятность каждой и выбрать наилучшую. Однако число таких последовательностей равно $N^T$ (где $N$ — число состояний, $T$ — длина наблюдений), что делает такой подход вычислительно невозможным.

Алгоритм Витерби решает эту проблему эффективно. Вместо перебора всех путей он на каждом шаге $t$ для каждого состояния $s_j$ находит **наиболее вероятный путь, заканчивающийся в этом состоянии**.

Для этого используются две переменные:
1.  $\delta_t(j)$: максимальная вероятность пути, который заканчивается в состоянии $s_j$ в момент времени $t$, породив первые $t$ наблюдений.
2.  $\psi_t(j)$: состояние в момент времени $t-1$, которое привело к максимальной вероятности $\delta_t(j)$. Эта переменная нужна для восстановления пути.

## Алгоритм

### Входные данные
*   [[Скрытая марковская модель|Модель HMM]] $\lambda = (A, B, \pi)$.
*   Последовательность наблюдений $O = (o_1, o_2, \dots, o_T)$.

### Шаги

1.  **Инициализация (t=1)**:
    Для каждого состояния $s_i$ вычисляем начальную вероятность с учётом первого наблюдения:
    $$
    \delta_1(i) = \pi_i \cdot b_i(o_1), \quad i = 1, \dots, N
    $$
    $$
    \psi_1(i) = 0
    $$

2.  **Рекурсия (t=2, ..., T)**:
    Для каждого состояния $s_j$ в момент времени $t$ находим наиболее вероятный предыдущий шаг:
    $$
    \delta_t(j) = \max_{1 \le i \le N} [\delta_{t-1}(i) \cdot a_{ij}] \cdot b_j(o_t)
    $$
    И запоминаем, из какого состояния $i$ был сделан этот шаг:
    $$
    \psi_t(j) = \arg\max_{1 \le i \le N} [\delta_{t-1}(i) \cdot a_{ij}]
    $$

3.  **Терминация**:
    Находим вероятность самого правдоподобного пути и его конечное состояние:
    $$
    P^* = \max_{1 \le i \le N} [\delta_T(i)]
    $$
    $$
    q_T^* = \arg\max_{1 \le i \le N} [\delta_T(i)]
    $$

4.  **Восстановление пути (Backtracking)**:
    Начиная с последнего состояния $q_T^*$, восстанавливаем всю последовательность, двигаясь назад по указателям $\psi$:
    $$
    q_t^* = \psi_{t+1}(q_{t+1}^*), \quad t = T-1, T-2, \dots, 1
    $$

### Сложность
*   **Время:** $O(N^2 \cdot T)$, где $N$ — количество скрытых состояний, $T$ — длина последовательности наблюдений.
*   **Память:** $O(N \cdot T)$ для хранения таблиц $\delta$ и $\psi$.

## Пример

Представим, что у нас есть модель погоды из примера в [[Скрытая марковская модель|HMM]] и мы наблюдаем последовательность `[Нет зонта, Есть зонт, Есть зонт]`.

Алгоритм Витерби пошагово вычислит наиболее вероятные пути, заканчивающиеся в состояниях `Солнечно` и `Дождь` для каждого дня.

*   **День 1 (Нет зонта)**: Вероятнее всего, было `Солнечно`.
*   **День 2 (Есть зонт)**: Алгоритм сравнит два варианта:
   1.  `Солнечно` -> `Дождь`
   2.  `Дождь` -> `Дождь`
   И выберет наиболее вероятный путь до состояния `Дождь` (и аналогично для `Солнечно`).
*   **День 3 (Есть зонт)**: Повторит процедуру.

После этого, начиная с наиболее вероятного состояния в День 3, он восстановит всю последовательность, например, `[Солнечно, Дождь, Дождь]`.

