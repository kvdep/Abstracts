---
aliases:
  - grad
  - gradient
  - градиенты
---
## Определение
Говорят, что **градиент** функции $f(x)$, где $x \in \mathbb{R}^n$, является вектором частных производных первого порядка, если его компоненты задаются выражением

$$
\nabla f(x) = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n} \right)^T,
$$

где:
* $n$ — размерность области определения функции;
* $\frac{\partial f}{\partial x_i}$ — частная производная функции $f$ по переменной $x_i$, вычисленная в точке $x$.

Градиент указывает направление наибыстрейшего возрастания функции, а его норма $\|\nabla f(x)\|$ характеризует скорость изменения функции в этом направлении. Для дифференцируемой функции в окрестности точки $x^{(k)}$ справедливо линейное приближение:

$$
f(x) \approx f(x^{(k)}) + \langle \nabla f(x^{(k)}), x - x^{(k)} \rangle,
$$

лежащее в основе метода градиентного спуска, где итерационный процесс определяется как:

$$
x^{(k+1)} = x^{(k)} - \lambda^{(k)} \nabla f(x^{(k)}), \quad \lambda^{(k)} > 0.
$$

## Пример
Для функции $f(x_1, x_2) = 4x_1^2 - 2x_1x_2 + x_2^2$ градиент в точке $(2, 1)$ равен:

$$
\nabla f(x) = \begin{pmatrix} 8x_1 - 2x_2 \\ -2x_1 + 2x_2 \end{pmatrix} \Bigg|_{(2,1)} = \begin{pmatrix} 14 \\ -2 \end{pmatrix}.
$$

Это означает, что в точке $(2, 1)$ функция быстрее всего растёт в направлении вектора $(14, -2)$, а оптимальный шаг $\lambda^{(k)}$ подбирается для минимизации $f(x^{(k+1)})$.