---
aliases:
  - t-SNE
  - t-распределённое стохастическое вложение соседей
  - t-distributed Stochastic Neighbor Embedding
---
# t-SNE (t-distributed Stochastic Neighbor Embedding)

**t-SNE** — это нелинейный метод понижения размерности, который используется в основном для **визуализации** многомерных данных. В отличие от [[Метод главных компонент (PCA)|PCA]], который стремится сохранить глобальную структуру данных (максимальную дисперсию), t-SNE фокусируется на сохранении **локальной структуры**, то есть на том, чтобы точки, близкие друг к другу в многомерном пространстве, оставались близкими и на карте низкой размерности (2D или 3D).

Это не алгоритм кластеризации, а скорее инструмент для исследования и визуальной оценки структуры данных.

## Основная идея

t-SNE работает в два этапа:

1.  **Построение распределения вероятностей в исходном пространстве:**
    *   Для каждой пары точек $(x_i, x_j)$ вычисляется условная вероятность $p_{j|i}$, которая отражает, насколько вероятно, что $x_i$ выберет $x_j$ в качестве своего соседа. Эта вероятность тем выше, чем ближе точки. Расчёт основан на Гауссовом распределении, центрированном в точке $x_i$.
    *   Эти вероятности делаются симметричными: $p_{ij} = (p_{j|i} + p_{i|j}) / 2n$.

2.  **Построение аналогичного распределения в низкоразмерном пространстве и их сближение:**
    *   Точки случайным образом размещаются в низкоразмерном пространстве (например, на плоскости).
    *   Для них вычисляется похожее [[Распределение]] вероятностей $q_{ij}$, но на основе **t-распределения Стьюдента** с одной степенью свободы. Использование t-распределения (с его "тяжёлыми хвостами") позволяет умеренно удалённым точкам в исходном пространстве оказаться дальше друг от друга на карте, что решает "проблему скученности" (crowding problem).
    *   С помощью градиентного спуска минимизируется **дивергенция Кульбака-Лейблера** между двумя распределениями ($P$ и $Q$). Этот процесс итеративно перемещает точки на низкоразмерной карте так, чтобы она наилучшим образом отражала соседские отношения в исходном пространстве.

## Ключевые гиперпараметры

Результат работы t-SNE сильно зависит от гиперпараметров:

*   **`perplexity` (перплексия, недоумение):** Самый важный параметр. Грубо говоря, он связан с ожидаемым числом ближайших соседей для каждой точки. Он определяет баланс между локальной и глобальной структурой данных.
    *   Типичные значения: от 5 до 50.
    *   Маленькая перплексия (~2-5) фокусируется на очень локальных связях.
    *   Большая перплексия (~30-50) учитывает больше соседей и может выявить более глобальные структуры.
*   **`learning_rate` (скорость обучения):** Шаг градиентного спуска. Слишком большой может привести к "разлёту" точек, слишком маленький — к медленной сходимости.
*   **`n_iter` (количество итераций):** Алгоритм итеративный, и ему нужно достаточно времени, чтобы "устаканиться".

## Сравнение с PCA

| Признак | [[[[Метод главных компонент (PCA)]] ([[Метод главных компонент (PCA)|PCA]])|[[Метод главных компонент (PCA)|PCA]]]] | t-SNE |
| :--- | :--- | :--- |
| **Тип** | Линейный | **Нелинейный** |
| **Цель** | Сохранение **глобальной** структуры (максимальной дисперсии) | Сохранение **локальной** структуры (соседских отношений) |
| **Интерпретация** | Оси (компоненты) имеют смысл (направления макс. дисперсии). Расстояния между точками сохраняются. | Оси не имеют смысла. **Расстояния между кластерами на графике неинформативны!** Важно лишь то, какие точки сгруппировались вместе. |
| **Выч. сложность** | Низкая, детерминированный | **Высокая**, итеративный, стохастический |
| **Применение** | Предобработка, понижение размерности для моделей | **Визуализация**, исследование данных |

**Важно:** Часто [[Метод главных компонент (PCA)|PCA]] используют для предварительного понижения размерности (например, до 50), а затем применяют t-SNE для финальной визуализации в 2D/3D. Это ускоряет работу t-SNE и может улучшить результаты.

## Пример на Python (с использованием Scikit-learn)

Используем набор данных `digits` для демонстрации способности t-SNE разделять сложные, нелинейные структуры.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.datasets import load_digits

def tsne_visualization():
    """
    Демонстрация t-SNE на наборе данных рукописных цифр.
    Снижение размерности с 64 до 2 для визуализации.
    """
    # 1. Загрузка данных
    digits = load_digits()
    X = digits.data  # 64 признака (8x8 изображение)
    y = digits.target # 10 классов (цифры от 0 до 9)

    # 2. Применение t-SNE
    # Параметры подобраны для наглядности
    tsne = TSNE(n_components=2, 
                perplexity=30, 
                learning_rate='auto', 
                n_iter=1000, 
                init='pca', # Инициализация с помощью PCA для стабильности
                random_state=42)
    
    X_tsne = tsne.fit_transform(X)

    # 3. Визуализация результатов
    plt.figure(figsize=(12, 9))
    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap=plt.cm.get_cmap("jet", 10), alpha=0.7)
    
    plt.title('t-SNE визуализация набора данных "digits"')
    plt.xlabel('t-SNE компонента 1')
    plt.ylabel('t-SNE компонента 2')
    plt.legend(handles=scatter.legend_elements()[0], labels=list(range(10)), title="Цифры")
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.show()

if __name__ == '__main__':
    tsne_visualization()

```

На графике видно, как t-SNE успешно сгруппировал точки, соответствующие одинаковым цифрам, в чётко различимые кластеры, несмотря на высокую исходную размерность данных.