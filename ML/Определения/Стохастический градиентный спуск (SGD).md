---
aliases:
  - стохастический градиентный спуск
  - SGD
  - Stochastic Gradient Descent
---
**Стохастический градиентный спуск (SGD)** — это итерационный метод оптимизации, который является стохастической (случайной) аппроксимацией [[Метод градиентного спуска|метода градиентного спуска]]. Он особенно эффективен для задач с большими наборами данных, типичных для машинного обучения.

## Основная идея

В задачах машинного обучения целевая функция (функция потерь) часто представляет собой сумму или среднее потерь по всем объектам обучающей выборки:
$$
F(x) = \frac{1}{N} \sum_{i=1}^{N} f_i(x)
$$
где $N$ — количество объектов в выборке, а $f_i(x)$ — функция потерь на $i$-м объекте.

Классический [[Метод градиентного спуска|градиентный спуск]] (Batch Gradient Descent) на каждом шаге требует вычисления полного [[Градиент|градиента]] $\nabla F(x) = \frac{1}{N} \sum_{i=1}^{N} \nabla f_i(x)$, что может быть очень затратно при большом $N$.

Идея SGD состоит в том, чтобы на каждой итерации аппроксимировать полный [[Градиент|градиент]] [[Градиент|градиентом]] функции потерь только по **одному случайно выбранному объекту** $i_k$:
$$
\nabla F(x^{(k)}) \approx \nabla f_{i_k}(x^{(k)})
$$
Таким образом, итерационный процесс выглядит так:
$$
x^{(k+1)} = x^{(k)} - \lambda_k \nabla f_{i_k}(x^{(k)})
$$
Каждый шаг получается очень быстрым, но "шумным". Траектория спуска к минимуму становится не плавной, а случайной, что, однако, может помочь "выпрыгивать" из локальных минимумов.

## Алгоритм

### Входные данные
*   Обучающая выборка $D = \{(d_1, y_1), \dots, (d_N, y_N)\}$.
*   Функция потерь $f_i(x)$ для каждого объекта.
*   Начальная точка $x^{(0)}$.
*   Скорость обучения $\lambda$.

### Псевдокод (для одной эпохи)

```
// Эпоха - один полный проход по всем данным

// 1. Перемешать данные в случайном порядке
Shuffle(D)

// 2. Пройти по всем объектам
for i = 1 to N:
    // Вычислить градиент по одному объекту
    grad = ∇f_i(x_current)
    
    // Сделать шаг в направлении антиградиента
    x_current = x_current - λ * grad

return x_current
```
Процесс повторяется на протяжении нескольких **эпох**.

## Сравнение с [[Метод градиентного спуска|пакетным градиентным спуском]]

| Характеристика         | Пакетный градиентный спуск (Batch GD)    | Стохастический градиентный спуск (SGD) |
| :--------------------- | :--------------------------------------- | :------------------------------------- |
| **Данные на итерации** | Вся обучающая выборка                    | Один случайный объект                  |
| **Скорость итерации**  | Медленная (зависит от $N$)               | Очень быстрая (не зависит от $N$)      |
| Точность [[Градиент]]      | Точный [[Градиент]]                          | "Шумная" оценка [[Градиент]]               |
| **Траектория**         | Прямое движение к минимуму               | Случайное блуждание вокруг минимума    |
| **Память**             | Требует много памяти для хранения данных | Требует очень мало памяти              |
| **Локальные минимумы** | Может застрять в локальном минимуме      | Шум помогает "перепрыгивать" через них |

### Mini-batch Gradient Descent

На практике чаще всего используется компромиссный вариант — **mini-batch SGD**. Вместо одного объекта на каждой итерации используется небольшая случайная подвыборка (батч, mini-batch) размером, например, 32, 64 или 128 объектов. Это позволяет:
1.  Снизить шум в оценке [[Градиент|градиента]] по сравнению с SGD.
2.  Добиться более стабильной сходимости.
3.  Эффективно использовать возможности параллельных вычислений на GPU.

## Применение

SGD и его модификации ([[Метод Adam|Adam]], RMSprop, Adagrad) являются де-факто стандартом для обучения большинства моделей глубокого обучения (Deep Learning) и других крупномасштабных задач машинного обучения.

