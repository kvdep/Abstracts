---
aliases:
  - индекс Джини
  - Gini Impurity
  - Gini Index
  - Джини
---
### Критерий неопределенности Джини (Gini Impurity)

Говорят, что **критерий неопределенности Джини** (или **индекс Джини**) — это метрика, используемая для оценки "чистоты" или "перемешанности" набора данных. Он наиболее часто применяется в алгоритмах машинного обучения, в частности, при построении **деревьев решений** (например, в алгоритме CART), для определения оптимального разделения данных на каждом узле.

Простыми словами, критерий Джини показывает вероятность того, что случайно выбранный элемент из набора будет неправильно классифицирован, если его класс будет присвоен случайным образом в соответствии с распределением классов в этом наборе.

#### Основная идея

*   **Чистый узел (Pure Node):** Если все элементы в узле принадлежат одному классу, то неопределенность равна нулю. Такой узел считается **чистым**.
*   **Нечистый узел (Impure Node):** Если элементы в узле равномерно распределены по разным классам, неопределенность максимальна.

Цель алгоритма построения дерева решений — минимизировать неопределенность дочерних узлов, делая их как можно более **чистыми**.

#### Формула

Критерий неопределенности Джини для одного узла рассчитывается по формуле:

$$
G = 1 - \sum_{i=1}^{C} p_i^2
$$

где:
*   $C$ — количество классов в наборе данных.
*   $p_i$ — доля (вероятность) элементов, принадлежащих классу $i$ в данном узле.

Значение критерия Джини всегда находится в диапазоне от $0$ до $1 - \frac{1}{C}$.
*   $G = 0$ означает полную чистоту (все элементы принадлежат одному классу).
*   Максимальное значение (например, $0.5$ для двух классов) означает максимальную неопределенность (классы распределены равномерно).

#### Пример расчета

Представим, что у нас есть узел с 10 элементами, которые нужно классифицировать на два класса: "Синий" и "Красный".

**Случай 1: Чистый узел**
*   10 "Синих", 0 "Красных".
*   $p_{синий} = \frac{10}{10} = 1$
*   $p_{красный} = \frac{0}{10} = 0$
*   $G = 1 - (1^2 + 0^2) = 1 - 1 = 0$
    Неопределенность равна нулю, узел абсолютно **чистый**.

**Случай 2: Максимально нечистый узел**
*   5 "Синих", 5 "Красных".
*   $p_{синий} = \frac{5}{10} = 0.5$
*   $p_{красный} = \frac{5}{10} = 0.5$
*   $G = 1 - (0.5^2 + 0.5^2) = 1 - (0.25 + 0.25) = 1 - 0.5 = 0.5$
    Неопределенность максимальна для двух классов.

**Случай 3: Смешанный узел**
*   7 "Синих", 3 "Красных".
*   $p_{синий} = \frac{7}{10} = 0.7$
*   $p_{красный} = \frac{3}{10} = 0.3$
*   $G = 1 - (0.7^2 + 0.3^2) = 1 - (0.49 + 0.09) = 1 - 0.58 = 0.42$
    Неопределенность ниже, чем в предыдущем случае, так как узел "ближе" к **чистому**.

### Использование в деревьях решений: Gini Gain

При построении дерева решений алгоритм должен выбрать, по какому признаку и какому значению этого признака разделить текущий узел на два дочерних. Чтобы сделать этот выбор, вычисляется **прирост информации** (Information Gain), который в случае с критерием Джини называется **Gini Gain**.

**Gini Gain** показывает, насколько уменьшится неопределенность после разделения узла. Алгоритм выбирает то разделение, которое дает максимальный **Gini Gain**.

Формула для расчета взвешенной неопределенности Джини для дочерних узлов:

$$
G_{split} = \sum_{k=1}^{m} \frac{N_k}{N} G_k
$$

где:
*   $m$ — количество дочерних узлов (обычно 2).
*   $N$ — общее количество элементов в родительском узле.
*   $N_k$ — количество элементов в $k$-м дочернем узле.
*   $G_k$ — критерий Джини для $k$-го дочернего узла.

**Gini Gain** вычисляется как разница между неопределенностью родительского узла и взвешенной неопределенностью дочерних узлов:

$$
\text{Gini Gain} = G_{parent} - G_{split}
$$

Алгоритм перебирает все возможные разделения и выбирает то, у которого `Gini Gain` максимален.

### Сравнение с Энтропией

Критерий Джини часто сравнивают с другим популярным критерием — **Энтропией** (используется в алгоритмах ID3, C4.5).

| Критерий | Преимущества | Недостатки |
| :--- | :--- | :--- |
| **Джини** | - Вычислительно проще и быстрее, так как не содержит логарифмов. <br> - Стремится изолировать наиболее частый класс в отдельную ветку. | - Менее чувствителен к изменениям в вероятностях классов. |
| **[[Энтропия]]** | - Более чувствителен к распределению классов, что иногда дает более сбалансированные деревья. | - Вычислительно сложнее из-за логарифмов. |

На практике результаты, полученные с использованием обоих критериев, очень похожи, и выбор между ними редко оказывает существенное влияние на итоговую точность модели. Критерий Джини часто используется по умолчанию из-за своей вычислительной эффективности.
