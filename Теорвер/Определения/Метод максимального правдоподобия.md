---
aliases:
  - метод максимального правдоподобия
  - ММП
  - MLE
  - Maximum Likelihood Estimation
---
**Метод максимального правдоподобия (ММП)** — это метод получения точечных оценок параметров статистической модели. Идея метода состоит в том, чтобы выбрать в качестве оценки такие значения параметров, при которых наблюдаемые данные являются наиболее "правдоподобными" (вероятными).

## Основная идея

Пусть имеется выборка $X = (x_1, x_2, \dots, x_n)$ из [[Распределение|распределения]] $p(x|\theta)$, зависящего от неизвестного параметра $\theta$.

1.  **Функция правдоподобия (Likelihood Function)**:
    Если предположить, что наблюдения в выборке независимы и одинаково распределены (i.i.d.), то совместная плотность вероятности (или функция вероятности для дискретного случая) всей выборки равна произведению плотностей для каждого наблюдения. Эта совместная плотность, рассматриваемая как функция от параметра $\theta$ при фиксированных данных $X$, называется функцией правдоподобия:
    $$
    L(\theta | X) = p(X | \theta) = \prod_{i=1}^{n} p(x_i | \theta)
    $$

2.  **Принцип максимального правдоподобия**:
    Оценка максимального правдоподобия $\hat{\theta}_{MLE}$ — это такое значение параметра $\theta$, которое максимизирует функцию правдоподобия:
    $$
    \hat{\theta}_{MLE} = \arg\max_{\theta} L(\theta | X)
    $$

3.  **Логарифмическая функция правдоподобия (Log-Likelihood)**:
    Поскольку логарифм является монотонно возрастающей функцией, максимизация $L(\theta | X)$ эквивалентна максимизации её логарифма $\mathcal{L}(\theta | X) = \ln L(\theta | X)$. Работать с логарифмом часто гораздо удобнее, так как он превращает произведение в сумму:
    $$
    \mathcal{L}(\theta | X) = \sum_{i=1}^{n} \ln p(x_i | \theta)
    $$
    Таким образом, задача сводится к:
    $$
    \hat{\theta}_{MLE} = \arg\max_{\theta} \mathcal{L}(\theta | X)
    $$

## Алгоритм

1.  Записать функцию правдоподобия $L(\theta | X)$ для данной выборки и модели.
2.  Перейти к логарифмической функции правдоподобия $\mathcal{L}(\theta | X)$.
3.  Найти [[Градиент|градиент]] (или производную, если параметр один) логарифмической функции правдоподобия по параметру $\theta$.
4.  Приравнять [[Градиент|градиент]] к нулю и решить полученное уравнение (или систему уравнений) относительно $\theta$.
    $$
    \frac{\partial \mathcal{L}(\theta | X)}{\partial \theta} = 0
    $$
5.  Убедиться, что найденное решение действительно является точкой максимума (например, проверив знак второй производной).

## Пример: Оценка параметра Бернулли

Пусть мы подбросили монету $n$ раз и получили $k$ "орлов" (1) и $n-k$ "решек" (0). Мы хотим оценить вероятность выпадения "орла" $p$.

*   **Модель**: [[Распределение]] Бернулли, $p(x|p) = p^x (1-p)^{1-x}$ для $x \in \{0, 1\}$.
*   **Выборка**: $X = (x_1, \dots, x_n)$, где $\sum x_i = k$.

1.  **Функция правдоподобия**:
    $$
    L(p | X) = \prod_{i=1}^{n} p^{x_i} (1-p)^{1-x_i} = p^{\sum x_i} (1-p)^{n - \sum x_i} = p^k (1-p)^{n-k}
    $$

2.  **Логарифмическая функция правдоподобия**:
    $$
    \mathcal{L}(p | X) = \ln(p^k (1-p)^{n-k}) = k \ln p + (n-k) \ln(1-p)
    $$

3.  **Производная**:
    $$
    \frac{d\mathcal{L}}{dp} = \frac{k}{p} - \frac{n-k}{1-p}
    $$

4.  **Решение**:
    $$
    \frac{k}{p} - \frac{n-k}{1-p} = 0 \implies k(1-p) = p(n-k) \implies k - kp = np - kp \implies k = np \implies p = \frac{k}{n}
    $$

Таким образом, оценка максимального правдоподобия для вероятности успеха в схеме Бернулли — это просто выборочная доля успехов $\hat{p}_{MLE} = \frac{k}{n}$, что интуитивно понятно.

## Свойства оценок ММП

Оценки, полученные методом максимального правдоподобия, обладают рядом хороших асимптотических свойств (при $n \to \infty$):
*   **[[Состоятельная оценка|Состоятельность]]**: Оценка сходится по вероятности к истинному значению параметра.
*   **Асимптотическая [[Несмещенная оценка|несмещённость]]**: Смещение оценки стремится к нулю.
*   **Асимптотическая [[Эффективная оценка|эффективность]]**: Дисперсия оценки достигает нижней границы Крамера-Рао.